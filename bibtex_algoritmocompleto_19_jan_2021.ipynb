{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2Fua0LiZm2JU",
        "PniSGgsc2huI",
        "guMfRu_LiYj6",
        "viH5JBC5-dQ7",
        "qMRHbyBAnqcw",
        "k37B59cUqXnc"
      ],
      "authorship_tag": "ABX9TyOD+waspAt/uUfboX++MyzK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lszam/bibtex/blob/main/bibtex_algoritmocompleto_19_jan_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Formatacao de bibliografias a partir de arquivos bibtex\n",
        "Programa Python para ler arquivos BibTeX e usar um arquivo .csl (Citation Style Language) para produzir uma lista de referências bibliográficas. Agradecimentos às recomendações em https://marcel.bollmann.me/blog/turning-bibtex-into-bibliographies-with-python/\n",
        "\n"
        "Autora: Luizemara Szameitat - luizemara@gmail.com - https://github.com/lszam/bibtex/ \n",
        "\n"
      ],
      "metadata": {
        "id": "PdlGoI0glo3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload do arquivo de lista de referencias."
      ],
      "metadata": {
        "id": "sD9NsORSwaev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "#Fazer upload do arquivo .csv\n",
        "uploaded=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "icYytFdfrRPF",
        "outputId": "1e5f33ec-9e81-4544-e3e9-1e6a801048b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-99295931-696e-4fc6-b21d-a4e078babcfa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-99295931-696e-4fc6-b21d-a4e078babcfa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving lista_de_referencias.csv to lista_de_referencias.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Criar arquivos BIBTEX"
      ],
      "metadata": {
        "id": "2Fua0LiZm2JU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Função DOI"
      ],
      "metadata": {
        "id": "PniSGgsc2huI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "\n",
        "def doi2bibfile_quotes(doi):\n",
        "      # Obtém os dados do DOI da publicação\n",
        "      url = f'https://doi.org/{doi}'\n",
        "      headers = {'Accept': 'application/x-bibtex'}\n",
        "      response = requests.get(url, headers=headers)\n",
        "\n",
        "      if response.status_code == 200:\n",
        "        print(f'Dados obtidos para o DOI {doi}')\n",
        "        # Conteúdo como BibTeX\n",
        "        bibtex_data = response.text\n",
        "\n",
        "        # Extrair informações\n",
        "        #Type and Nickname\n",
        "        type_match = re.search(r'@([^{}]+){([^,]+),', bibtex_data)\n",
        "        entry_type = type_match.group(1)\n",
        "        nick = type_match.group(2)\n",
        "        #Title\n",
        "        title_match = re.search(r'title={([^}]+)}', bibtex_data)\n",
        "        title = title_match[1].replace(\",\", \"*\")\n",
        "        #Author\n",
        "        author_match = re.search(r'author={([^}]+)}', bibtex_data)\n",
        "        author = author_match[1].replace(\",\", \"*\")\n",
        "        #Year\n",
        "        year_match = re.search(r'year={(\\d+)}', bibtex_data)\n",
        "        year = year_match.group(1)\n",
        "\n",
        "        #Volume\n",
        "        volume_match = re.search(r'volume={([^}]+)}', bibtex_data)\n",
        "        if author_match is not None:\n",
        "          volume = volume_match[1]\n",
        "        else:\n",
        "          volume = \"\"\n",
        "        #Number\n",
        "        number_match = re.search(r'number={([^}]+)}', bibtex_data)\n",
        "        if number_match is not None:\n",
        "          number = number_match[1]\n",
        "        else:\n",
        "          number = \"\"\n",
        "        #Pages\n",
        "        pages_match = re.search(r'pages={([^}]+)}', bibtex_data)\n",
        "        if pages_match is not None:\n",
        "          pages = pages_match[1]\n",
        "        else:\n",
        "          pages = \"\"\n",
        "        #Journal\n",
        "        journal_match = re.search(r'journal={([^}]+)}', bibtex_data)\n",
        "        if journal_match is not None:\n",
        "          journal = journal_match[1]\n",
        "        else:\n",
        "          journal = \"\"\n",
        "        #Publisher\n",
        "        publisher_match = re.search(r'publisher={([^}]+)}', bibtex_data)\n",
        "        if publisher_match is not None:\n",
        "          publisher = publisher_match[1]\n",
        "        else:\n",
        "          publisher = \"\"\n",
        "        #Keywords\n",
        "        keywords_match = re.search(r'keywords={([^}]+)}', bibtex_data)\n",
        "        if keywords_match is not None:\n",
        "          keywords = keywords_match[1]\n",
        "        else:\n",
        "          keywords = \"\"\n",
        "        #Abstract\n",
        "        abstract_match = re.search(r'abstract={([^}]+)}', bibtex_data)\n",
        "        if abstract_match is not None:\n",
        "          abstract = abstract_match[1]\n",
        "        else:\n",
        "          abstract = \"\"\n",
        "        #ISSN\n",
        "        issn_match = re.search(r'issn={([^}]+)}', bibtex_data)\n",
        "        if issn_match is not None:\n",
        "          issn = issn_match[1]\n",
        "        else:\n",
        "          issn = \"\"\n",
        "        #URL\n",
        "        url_match = re.search(r'url={([^}]+)}', bibtex_data)\n",
        "        if url_match is not None:\n",
        "          url = url_match[1]\n",
        "        else:\n",
        "          url = \"\"\n",
        "\n",
        "        bib_dict = {\"title\" : title,\n",
        "                    \"author\" : author,\n",
        "                    \"year\" : year,\n",
        "                    \"volume\" : volume,\n",
        "                    \"number\" : number,\n",
        "                    \"pages\" : pages,\n",
        "                    \"journal\" : journal,\n",
        "                    \"publisher\" : publisher,\n",
        "                    \"keywords\" : keywords,\n",
        "                    \"abstract\" : abstract,\n",
        "                    \"issn\" : issn,\n",
        "                    \"url\" : url,\n",
        "                    \"doi\" : doi}\n",
        "\n",
        "        # Nome do arquivo de saída\n",
        "        author = author_match.group(1).split(',')[0]\n",
        "        title = title_match.group(1).split()[:2]\n",
        "        title = ''.join(title)\n",
        "        output_filename = f'{author}{year}_{title}.bib'\n",
        "\n",
        "        try:\n",
        "          with open(output_filename, 'w', encoding='utf-8') as bibfile:\n",
        "            head = f'@{entry_type}'+\"{\"+ f'{nick},'\n",
        "            bibfile.write(head + '\\r\\n')\n",
        "            for item in bib_dict:\n",
        "              if \"*\" in bib_dict[item]:\n",
        "                bib_dict[item] = bib_dict[item].replace('*', ',')\n",
        "              new_line = f'{item}=\"{bib_dict[item]}\",'\n",
        "              bibfile.write(new_line + '\\r\\n')\n",
        "            bibfile.write('}')\n",
        "            print(f'Arquivo .bib salvo para o DOI {doi}')\n",
        "        except:\n",
        "          print(f'Não foi possível salvar o arquivo .bib para o DOI {doi}')\n",
        "\n",
        "      else:\n",
        "        print(f'Não foi possível obter os dados para o DOI {doi}')"
      ],
      "metadata": {
        "id": "KHQD7qmE6bS_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Função ISBN"
      ],
      "metadata": {
        "id": "guMfRu_LiYj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def isbn2bibfile_quotes(isbn):\n",
        "    # URL da API do Google Books\n",
        "    url = f\"https://www.googleapis.com/books/v1/volumes?q=isbn:{isbn}\"\n",
        "\n",
        "    try:\n",
        "        # Solicitacao para a API do Google\n",
        "        response = requests.get(url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "          print(f'Dados obtidos para o ISBN {isbn}')\n",
        "          book_data = response.json() # Converte a resposta JSON em dict Python\n",
        "\n",
        "          if 'items' in book_data:\n",
        "              book_info = book_data['items'][0]['volumeInfo']\n",
        "              # Extrair informacoes\n",
        "              title_match = book_info.get('title', 'N/A')\n",
        "              author_match = book_info.get('authors', 'N/A')\n",
        "              subtitle_match = book_info.get('subtitle', 'N/A')\n",
        "              publisher_match = book_info.get('publisher', 'N/A')\n",
        "              published_date_match = book_info.get('publishedDate', 'N/A')\n",
        "              pageCount_match = book_info.get('pageCount', 'N/A')\n",
        "              keywords_match = book_info.get('keywords', 'N/A')\n",
        "\n",
        "              #Infos com tags usadas no padrao bibtex\n",
        "              bib_dict = {\"title\" : title_match,\n",
        "                          \"subtitle\" : subtitle_match,\n",
        "                          \"author\" : author_match[0],\n",
        "                          \"year\" : published_date_match,\n",
        "                          \"pages\" : pageCount_match,\n",
        "                          \"publisher\" : publisher_match,\n",
        "                          \"keywords\" : keywords_match,\n",
        "                          \"isbn\" : isbn\n",
        "                            }\n",
        "\n",
        "              entry_type = 'book'\n",
        "              nick = f'{author_match[0].split()[-1]}{published_date_match}book'\n",
        "\n",
        "              try:\n",
        "                with open(f'{nick}.bib', 'w', encoding='utf-8') as bibfile:\n",
        "                  head = f'@{entry_type}'+\"{\"+ f'{nick},'\n",
        "                  bibfile.write(head + '\\r\\n')\n",
        "                  # print(head + '\\r\\n')\n",
        "                  for item in bib_dict:\n",
        "                    new_line = f'{item}=\"{bib_dict[item]}\",'\n",
        "                    # print(new_line + '\\r\\n')\n",
        "                    bibfile.write(new_line + '\\r\\n')\n",
        "                  bibfile.write('}')\n",
        "                  print(f'Arquivo .bib salvo para o ISBN {isbn}')\n",
        "              except:\n",
        "                print(f'Não foi possível salvar o arquivo .bib para o ISBN {isbn}')\n",
        "\n",
        "          else:\n",
        "              # return {'error': 'Livro não encontrado'}\n",
        "              print('Erro: Livro não encontrado')\n",
        "\n",
        "        else:\n",
        "          # return {'error': 'Falha na solicitação à API'}\n",
        "          print('Erro: Falha na solicitação à API')\n",
        "\n",
        "    except Exception as e:\n",
        "                    # return {'error': str(e)}\n",
        "                    print('error', str(e))\n",
        "\n",
        "\n",
        "# Exemplo de uso da função\n",
        "# isbn = '978-90-5744-139-4'  # Substitua pelo ISBN do livro desejado\n",
        "# isbn2bibfile_quotes(isbn)"
      ],
      "metadata": {
        "id": "S_XlvXs_AsUu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ler o arquivo .csv com lista de números DOI e ISBN"
      ],
      "metadata": {
        "id": "viH5JBC5-dQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def read_doi_csv(csv_file):\n",
        "  df = pd.read_csv(csv_file)\n",
        "  doi_list = df['doi'].tolist()\n",
        "  return doi_list\n",
        "\n",
        "def main():\n",
        "  csv_file = list(uploaded.keys())[0]\n",
        "  doi_list = read_doi_csv(csv_file)\n",
        "  for item in doi_list:\n",
        "    if item.startswith('10'): #executa se o registro for um doi\n",
        "      doi2bibfile_quotes(item)\n",
        "    else:\n",
        "      isbn2bibfile_quotes(item)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s26wPYcy9L3c",
        "outputId": "bdae18b2-3b20-4fbb-8b6a-a79c7ac47b24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados obtidos para o DOI 10.1029/2020JB021183\n",
            "Arquivo .bib salvo para o DOI 10.1029/2020JB021183\n",
            "Dados obtidos para o DOI 10.1016/j.jsames.2021.103218\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.jsames.2021.103218\n",
            "Dados obtidos para o ISBN 978-90-5744-139-4\n",
            "Arquivo .bib salvo para o ISBN 978-90-5744-139-4\n",
            "Dados obtidos para o DOI 10.1016/j.epsl.2012.09.012\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.epsl.2012.09.012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Criar lista de referencias (saída em HTML)"
      ],
      "metadata": {
        "id": "wygYSnOpm6zH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importações e instalações"
      ],
      "metadata": {
        "id": "qMRHbyBAnqcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pybtex -q\n",
        "!pip install citeproc-py -q\n",
        "!pip install --no-cache-dir --force-reinstall git+https://github.com/sciunto-org/python-bibtexparser@main -q\n",
        "#instalar estilos\n",
        "!pip install citeproc-py citeproc-py-styles -q\n",
        "# !pip install gitpython -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV0gjYRCnv5e",
        "outputId": "1c6fa1a6-6a39-4b2f-b598-f17e73bb58bc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.4/561.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.9/179.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bibtexparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from citeproc.source.bibtex import BibTeX\n",
        "from citeproc import CitationStylesStyle, CitationStylesBibliography, formatter\n",
        "from citeproc_styles import get_style_filepath\n",
        "from citeproc import Citation, CitationItem\n",
        "from google.colab import files\n",
        "import io\n",
        "# import git"
      ],
      "metadata": {
        "id": "ZnQzRMQHn5zB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Abrir arquivos BibTeX da pasta\n",
        "folder_path = \"/content/\"\n",
        "entries = []\n",
        "biblist = []\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.bib'):\n",
        "      try:\n",
        "          file_path = os.path.join(folder_path, filename)\n",
        "          with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            bib_src = BibTeX(file)\n",
        "            biblist.append(bib_src)  # lista de dicionários\n",
        "      except:\n",
        "          print(\"Erro ao ler dados do arquivo.\", filename)\n",
        "biblist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhZYJg7YoF-2",
        "outputId": "787ea68b-966c-45a1-d522-c926be4e0e0c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/citeproc/source/bibtex/bibtex.py:89: UserWarning: Unsupported BibTeX field 'keywords'\n",
            "  warn(\"Unsupported BibTeX field '{}'\".format(field))\n",
            "/usr/local/lib/python3.10/dist-packages/citeproc/source/bibtex/bibtex.py:89: UserWarning: Unsupported BibTeX field 'url'\n",
            "  warn(\"Unsupported BibTeX field '{}'\".format(field))\n",
            "/usr/local/lib/python3.10/dist-packages/citeproc/source/bibtex/bibtex.py:89: UserWarning: Unsupported BibTeX field 'subtitle'\n",
            "  warn(\"Unsupported BibTeX field '{}'\".format(field))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'angiboust_2012': Reference(angiboust_2012)},\n",
              " {'amaru2007book': Reference(amaru2007book)},\n",
              " {'almeida_2021': Reference(almeida_2021)},\n",
              " {'affonso_2021': Reference(affonso_2021)}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Formatação do texto no estilo da revista\n"
      ],
      "metadata": {
        "id": "TNUldPI_oifY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Verifique se a revista possui um modelo .CSL (Citation Style Language) cadastrado, e o nome a ser usado.\n",
        "Insira o nome na variável abaixo, como cadastrado no repositório:"
      ],
      "metadata": {
        "id": "oXBS-HjEp3D2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Estilo pretendido - revista\n",
        "csl_model = \"journal-of-geophysical-research-solid-earth\""
      ],
      "metadata": {
        "id": "g2T77qoco0TJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Formatar e salvar arquivo de saída"
      ],
      "metadata": {
        "id": "k37B59cUqXnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Abrir CSL do repositorio público\n",
        "stylepath = get_style_filepath(csl_model)\n",
        "bib_style = CitationStylesStyle(stylepath, validate=False)\n",
        "\n",
        "output_text = ''  #acumular as referências em uma string\n",
        "\n",
        "for bib in biblist:\n",
        "    for key, value in bib.items():\n",
        "        library = CitationStylesBibliography(bib_style, bib, formatter.html)\n",
        "        item = CitationItem(key)\n",
        "        library.register(Citation([item]))\n",
        "        text = ''.join(library.style.render_bibliography([item])[0])\n",
        "        print(\"- \" + text)\n",
        "        output_text += '<div>' + text + '</div>\\n'  #colocar a tag <div> em cada item\n",
        "\n",
        "#Salva no formato HTML\n",
        "with open('output-references.html', 'w') as f:\n",
        "    f.write(output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o157EpZ8oeKX",
        "outputId": "f4261243-c7cb-4037-ba6b-27c3cdfee1d1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Angiboust, S., Wolf, S., Burov, E., Agard, P., &amp; Yamato, P..  (2012). Effect of fluid circulation on subduction interface tectonic processes: Insights from thermo-mechanical numerical modelling. <i>Earth and Planetary Science Letters</i>, <i>357–358</i>, 238–248. https://doi.org/10.1016/j.epsl.2012.09.012\n",
            "- Amaru, M..  (2007). <i>Global travel time tomography with 3-D reference models</i> (p. 174). N/A.\n",
            "- Almeida, J., Heilbron, M., Guedes, E., Neubauer, F., Manfred, B., Klausen, M. B., et al..  (2021). Pre-to-syn-rift tholeiitic magmatism in a transtensive hyperextended continental margin: Onshore and offshore magmatism of the Campos Basin, SE Brazil. <i>Journal of South American Earth Sciences</i>, <i>108</i>, 103218. https://doi.org/10.1016/j.jsames.2021.103218\n",
            "- Affonso, G. M. P. C., Rocha, M. P., Costa, I. S. L., Assumpção, M., Fuck, R. A., Albuquerque, D. F., et al..  (2021). Lithospheric Architecture of the Paranapanema Block and Adjacent Nuclei Using Multiple‐Frequency P‐Wave Seismic Tomography. <i>Journal of Geophysical Research: Solid Earth</i>, <i>126</i>(4). https://doi.org/10.1029/2020JB021183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salvar o arquivo de saída na pasta Downloads local"
      ],
      "metadata": {
        "id": "73mRzVM7xv90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('output-references.html')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "28i_kQ_XxaQF",
        "outputId": "035dea4e-4cd3-47e8-ce23-39c54d37eef5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4bc6914b-1841-4d50-a4af-f0b4cb1a72a5\", \"output-references.html\", 1175)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lszam/bibtex/blob/main/bibtex_algoritmocompleto_22_jan_2024_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdlGoI0glo3R"
      },
      "source": [
        "#Formatacao de bibliografias a partir de arquivos bibtex\n",
        "Programa Python para criar e ler arquivos BibTeX, e usar um arquivo .csl (Citation Style Language) para produzir uma lista de referências bibliográficas. Agradecimentos às recomendações em https://marcel.bollmann.me/blog/turning-bibtex-into-bibliographies-with-python/\n",
        "\n",
        "Orientações em português para conteúdo do arquivo .bib: chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/http://paginapessoal.utfpr.edu.br/jamhour/publicacoes/arquivos/00_Compilado_JabRef_dez2015.pdf\n",
        "\n",
        "\n",
        "######Autora: Luizemara Szameitat - Repositorio GitHub https://github.com/lszam/bibtex/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD9NsORSwaev"
      },
      "source": [
        "Upload do arquivo de lista de referencias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "icYytFdfrRPF",
        "outputId": "92c66948-5a88-4e52-ee2f-22b499395411"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-db693b0f-b6f9-4286-a557-ca090b19f3e6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-db693b0f-b6f9-4286-a557-ca090b19f3e6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving lista_de_referencias.csv to lista_de_referencias.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "#Fazer upload do arquivo .csv\n",
        "uploaded=files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fua0LiZm2JU"
      },
      "source": [
        "#Criar arquivos BIBTEX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cp2Ew_M1ZKa",
        "outputId": "4ab9d9eb-38a5-4a20-bb7e-27af4f657e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sobrenome1, Nome1 NomeDoMeio1\n",
            "Amaru, Maisha\n"
          ]
        }
      ],
      "source": [
        "def author_surname_name(author):\n",
        "  '''\n",
        "  Formatting author's name as 'LastSurname, Name OtherSurnames'\n",
        "  '''\n",
        "  author_split = author.split()\n",
        "  if ',' in author_split[0]:\n",
        "    return author\n",
        "  else:\n",
        "    if len(author_split) > 1:\n",
        "      return author_split[-1] + \", \" + \" \".join(author_split[:-1])\n",
        "    else:\n",
        "      return author\n",
        "\n",
        "# Exemplos de uso\n",
        "author1 = \"Sobrenome1, Nome1 NomeDoMeio1\"\n",
        "# author2 = \"Nome2 NomeDoMeio2 Sobrenome2\"\n",
        "author2 = \"Maisha Amaru\"\n",
        "formatted_author1 = author_surname_name(author1)\n",
        "formatted_author2 = author_surname_name(author2)\n",
        "print(formatted_author1)\n",
        "print(formatted_author2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lifp8n3mUgp0"
      },
      "source": [
        "##Função DOI\n",
        "Tratada a incompatibilidade, converte a entrada para utf-8; tratada a entrada do site Zenodo, espaços entorno do '='.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkuEong8Sw23"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import re\n",
        "import chardet\n",
        "\n",
        "def doi2bibfile_quotes(doi):\n",
        "    error_log = list()\n",
        "    doi_pages = ['https://doi.org/',\n",
        "                 'https://dx.doi.org/',\n",
        "                 'http://doi.org/',\n",
        "                 'http://dx.doi.org/',\n",
        "                 'https://zenodo.org/doi/']\n",
        "    headers = {'Accept': 'application/x-bibtex'}\n",
        "\n",
        "    for item in doi_pages:\n",
        "        try:\n",
        "            url = f'{item}{doi}'\n",
        "            response = requests.get(url, headers=headers)\n",
        "            encoding = chardet.detect(response.content)['encoding']\n",
        "            response_utf8 = response.content.decode('utf-8', 'replace')\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                # print(f'{url} : dados obtidos com sucesso')\n",
        "                break\n",
        "        except Exception as e:\n",
        "            print('EXCEPTION: URL', url, str(e))\n",
        "            error_log.append([doi, url, str(e)])\n",
        "\n",
        "    if response:\n",
        "        # Conteúdo como BibTeX\n",
        "        bibtex_data = response_utf8\n",
        "\n",
        "        #Type, Nickname\n",
        "        type_match = re.search(r'@([^{}]+){([^,]+),', bibtex_data)\n",
        "        entry_type = str(f'{type_match.group(1)}')\n",
        "        nick = type_match.group(2)\n",
        "\n",
        "        # Informações essenciais: title, author, year\n",
        "        try:\n",
        "\n",
        "          # Title\n",
        "          title_match = re.search(r'title\\s*=\\s*{([^}]+)}', bibtex_data)\n",
        "          title = title_match[1].replace(\",\", \"*\")\n",
        "\n",
        "          # Author\n",
        "          author_match = re.search(r'author\\s*=\\s*{([^}]+)}', bibtex_data)\n",
        "          author_list = author_match.group(1).split('and')\n",
        "          # Padronizar o nome dos autores como sobrenome, nome\n",
        "          # pois este é o padrão mais comum em lista de referencias para artigos\n",
        "          author_checked_list = list()\n",
        "          for a in author_list:\n",
        "            author_name = author_surname_name(a)\n",
        "            author_checked_list.append(a)\n",
        "          author = \"and\".join(author_checked_list)\n",
        "\n",
        "          # # Substituição temporaria para diferenciar fim de linha com vírgula dos autores\n",
        "          # author = author_match[1].replace(\",\", \"*\")\n",
        "\n",
        "          # Year\n",
        "          year_match = re.search(r'year\\s*=\\s*{(\\d+)}', bibtex_data)\n",
        "          year = year_match.group(1)\n",
        "        except Exception as e:\n",
        "          print(f'Exception on basic information (title, author, year): {e}')\n",
        "\n",
        "        # Volume\n",
        "        volume_match = re.search(r'volume\\s*=\\s*{([^}]+)}', bibtex_data)\n",
        "        if volume_match is not None:\n",
        "          volume = volume_match[1]\n",
        "        else:\n",
        "          volume = \"\"\n",
        "        # Number\n",
        "        number_match = re.search(r'number\\s*=\\s*{([^}]+)}', bibtex_data)\n",
        "        if number_match is not None:\n",
        "          number = number_match[1]\n",
        "        else:\n",
        "          number = \"\"\n",
        "        # Pages\n",
        "        pages_match = re.search(r'pages\\s*=\\s*{([^}]+)}', bibtex_data)\n",
        "        if pages_match is not None:\n",
        "          pages = pages_match[1]\n",
        "        else:\n",
        "          pages = \"\"\n",
        "        # Journal\n",
        "        journal_match = re.search(r'journal={([^}]+)}', bibtex_data)\n",
        "        if journal_match is not None:\n",
        "          journal = journal_match[1]\n",
        "        else:\n",
        "          journal = \"\"\n",
        "        # Publisher\n",
        "        publisher_match = re.search(r'publisher\\s*=\\s*{([^}]+)}', bibtex_data)\n",
        "        if publisher_match is not None:\n",
        "          publisher = publisher_match[1]\n",
        "        else:\n",
        "          publisher = \"\"\n",
        "        # Keywords\n",
        "        keywords_match = re.search(r'keywords\\s*=\\s*{([^}]+)}', bibtex_data)\n",
        "        if keywords_match is not None:\n",
        "          keywords = keywords_match[1]\n",
        "        else:\n",
        "          keywords = \"\"\n",
        "        # Abstract\n",
        "        abstract_match = re.search(r'abstract\\s*=\\s*{([^}]+)}', bibtex_data)\n",
        "        if abstract_match is not None:\n",
        "          abstract = abstract_match[1]\n",
        "        else:\n",
        "          abstract = \"\"\n",
        "        # ISSN\n",
        "        issn_match = re.search(r'issn\\s*=\\s*{([^}]+)}', bibtex_data)\n",
        "        if issn_match is not None:\n",
        "          issn = issn_match[1]\n",
        "        else:\n",
        "          issn = \"\"\n",
        "        # URL\n",
        "        url_match = re.search(r'url\\s*=\\s*{([^}]+)}', bibtex_data)\n",
        "        if url_match is not None:\n",
        "          url = url_match[1]\n",
        "        else:\n",
        "          url = \"\"\n",
        "        # Copyright\n",
        "        copyright_match = re.search(r'copyright\\s*=\\s*{([^}]+)}', bibtex_data)\n",
        "        if copyright_match is not None:\n",
        "          copyright = copyright_match[1]\n",
        "        else:\n",
        "          copyright = \"\"\n",
        "\n",
        "        bib_dict = {\"entry_type\" : entry_type,\n",
        "                    \"id\" : nick,\n",
        "                    \"title\" : title,\n",
        "                    \"author\" : author,\n",
        "                    \"year\" : year,\n",
        "                    \"volume\" : volume,\n",
        "                    \"number\" : number,\n",
        "                    \"pages\" : pages,\n",
        "                    \"journal\" : journal,\n",
        "                    \"publisher\" : publisher,\n",
        "                    \"keywords\" : keywords,\n",
        "                    \"abstract\" : abstract,\n",
        "                    \"issn\" : issn,\n",
        "                    \"url\" : url,\n",
        "                    \"doi\" : doi,\n",
        "                    \"copyright\" : copyright}\n",
        "\n",
        "\n",
        "        # Nome do arquivo de saída\n",
        "        author_part = author_match.group(1).split(',')[0]# primeiro nome\n",
        "        title_part = title_match.group(1).split()[:2]# duas primeira palavras\n",
        "        title_part[0] = re.sub(r'[\\/:*?\",<>|]', '_', title_part[0]) # caracteres invalidos\n",
        "        title_part[1] = re.sub(r'[\\/:*?\",<>|]', '_', title_part[1]) # caracteres invalidos\n",
        "        title_part = ''.join(title_part)\n",
        "        output_filename = f'{author_part}{year}_{title_part}.bib'\n",
        "\n",
        "        # Gravar arquivo .bib\n",
        "        try:\n",
        "            with open(output_filename, 'w', encoding='utf-8') as bibfile:\n",
        "              head = f'@{entry_type}'+\"{\"+ f'{nick}'\n",
        "              bibfile.write(head + ',\\r\\n')\n",
        "              for i, (key, value) in enumerate(bib_dict.items()):\n",
        "                if i > 1 and value != \"\":  # Ignora os 2 primeiros itens\n",
        "                    if \"*\" in value:\n",
        "                        value = value.replace('*', ',')\n",
        "                    new_line = f'{key}=\"{value}\",'\n",
        "                    bibfile.write(new_line + '\\r\\n')\n",
        "              bibfile.write('}')\n",
        "              print(f'Arquivo .bib salvo para o DOI {doi}')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'Exception na gravação do arquivo .bib para o DOI {doi}: ', str(e))\n",
        "            print(\"SOURCE:\", response_utf8)\n",
        "            error_log.append([doi, str(\"Exception: \"+str(e))])\n",
        "\n",
        "    else:\n",
        "        print(f'Response error: Não foi possível obter os dados para o DOI {doi}')\n",
        "        error_log.append([doi, \"Não foi possível obter os dados para o DOI\"])\n",
        "\n",
        "    return (bib_dict, error_log)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guMfRu_LiYj6"
      },
      "source": [
        "##Função ISBN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_XlvXs_AsUu",
        "outputId": "c595512b-0798-4a2a-b30f-b48c6a3dad43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo .bib salvo para o ISBN 978-90-5744-139-4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'entry_type': 'book',\n",
              "  'id': 'Amaru2007book',\n",
              "  'title': 'Global travel time tomography with 3-D reference models',\n",
              "  'subtitle': 'Globale reistijdentomografie met 3-D referentiemodellen',\n",
              "  'author': 'Amaru, Maisha',\n",
              "  'year': '2007',\n",
              "  'pages': 174,\n",
              "  'publisher': '',\n",
              "  'keywords': '',\n",
              "  'isbn': '978-90-5744-139-4'},\n",
              " [])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "def isbn2bibfile_quotes(isbn):\n",
        "    # URL da API do Google Books\n",
        "    url = f\"https://www.googleapis.com/books/v1/volumes?q=isbn:{isbn}\"\n",
        "\n",
        "    error_log = list()\n",
        "\n",
        "    try:\n",
        "        # Solicitacao para a API do Google\n",
        "        response = requests.get(url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "          book_data = response.json() # Converte a resposta JSON em dict Python\n",
        "\n",
        "          if 'items' in book_data:\n",
        "              book_info = book_data['items'][0]['volumeInfo']\n",
        "              # Extrair informacoes\n",
        "              title_match = book_info.get('title', '')\n",
        "              author_match = book_info.get('authors', '')\n",
        "              subtitle_match = book_info.get('subtitle', '')\n",
        "              publisher_match = book_info.get('publisher', '')\n",
        "              published_date_match = book_info.get('publishedDate', '')\n",
        "              pageCount_match = book_info.get('pageCount', '')\n",
        "              keywords_match = book_info.get('keywords', '')\n",
        "\n",
        "              id = f'{author_match[0].split()[-1]}{published_date_match}book'\n",
        "              id = re.sub(r'[\\/:*?\",<>|]-', '_', id) # caracteres invalidos\n",
        "              entry_type = 'book'\n",
        "\n",
        "              # Author\n",
        "              author_list = author_match[0].split('and')\n",
        "              # Padronizar o nome dos autores como sobrenome, nome\n",
        "              # pois este é o padrão mais comum em lista de referencias para artigos\n",
        "              author_checked_list = list()\n",
        "              for a in author_list:\n",
        "                author_name = author_surname_name(a)\n",
        "                author_checked_list.append(author_name)\n",
        "              author_checked = \"and\".join(author_checked_list)\n",
        "\n",
        "              # # Substituição temporaria para diferenciar fim de linha com vírgula dos autores\n",
        "              # author_checked = author_checked.replace(\",\", \"#\")\n",
        "              # print ('CONTROLE')\n",
        "\n",
        "              #Infos com tags usadas no padrao bibtex\n",
        "              bib_dict = {\"entry_type\" : entry_type,\n",
        "                          \"id\" : id,\n",
        "                          \"title\" : title_match,\n",
        "                          \"subtitle\" : subtitle_match,\n",
        "                          \"author\" : author_checked,\n",
        "                          \"year\" : published_date_match,\n",
        "                          \"pages\" : pageCount_match,\n",
        "                          \"publisher\" : publisher_match,\n",
        "                          \"keywords\" : keywords_match,\n",
        "                          \"isbn\" : isbn}\n",
        "\n",
        "              try:\n",
        "                with open(f'{id}.bib', 'w', encoding='utf-8') as bibfile:\n",
        "                  head = f'@{entry_type}'+\"{\"+ f'{id},'\n",
        "                  bibfile.write(head + '\\r\\n')\n",
        "                  # print(head + '\\r\\n')\n",
        "                  for item in bib_dict:\n",
        "                    # if \"*\" in bib_dict[item]:\n",
        "                    new_line = f'{item}=\"{bib_dict[item]}\",'\n",
        "                    # print(new_line + '\\r\\n')\n",
        "                    bibfile.write(new_line + '\\r\\n')\n",
        "                  bibfile.write('}')\n",
        "                  print(f'Arquivo .bib salvo para o ISBN {isbn}')\n",
        "              except:\n",
        "                print(f'*** ERRO: Não foi possível salvar o arquivo .bib para o ISBN {isbn}')\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "       # return {'error': str(e)}\n",
        "       print('ERRO:', str(e))\n",
        "       error_log.append([isbn, str(e)])\n",
        "\n",
        "    return (bib_dict, error_log)\n",
        "\n",
        "\n",
        "# Exemplo de uso da função\n",
        "isbn = '978-90-5744-139-4'  # Substitua pelo ISBN do livro desejado\n",
        "isbn2bibfile_quotes(isbn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viH5JBC5-dQ7"
      },
      "source": [
        "##Ler o arquivo .csv com lista de números DOI e ISBN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s26wPYcy9L3c",
        "outputId": "471b28cd-2d46-47e8-fe17-5ddfac1a5fac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo .bib salvo para o DOI 10.1029/2020JB021183\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.jsames.2021.103218\n",
            "Arquivo .bib salvo para o ISBN 978-90-5744-139-4\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.epsl.2012.09.012\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.jsames.2022.104062\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.precamres.2016.09.014\n",
            "Arquivo .bib salvo para o ISBN 978-0-521-84396-6\n",
            "Arquivo .bib salvo para o DOI 10.1126/sciadv.1500815\n",
            "Arquivo .bib salvo para o DOI 10.1007/978-3-319-61667-4_8\n",
            "Arquivo .bib salvo para o DOI 10.1016/S0166-2635(09)01620-X\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.lithos.2020.105484\n",
            "Arquivo .bib salvo para o DOI 10.1016/0264-3707(95)00028-8\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.jsames.2012.07.006\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.jvolgeores.2017.11.011\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.precamres.2021.106394\n",
            "Arquivo .bib salvo para o DOI 10.1002/2016GC006369\n",
            "Arquivo .bib salvo para o DOI 10.1016/0012-821X(96)00023-4\n",
            "*** Exception para o código 9782917310267:local variable 'bib_dict' referenced before assignment\n",
            "Arquivo .bib salvo para o DOI 10.1130/2007.2430(29)\n",
            "Arquivo .bib salvo para o DOI 10.1029/JB075i014p02625\n",
            "Arquivo .bib salvo para o DOI 10.1016/0031-9201(81)90046-7\n",
            "Arquivo .bib salvo para o DOI 10.1002/2014JB011561\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.precamres.2017.01.029\n",
            "Arquivo .bib salvo para o DOI 10.1130/0091-7613(1993)021<0459:GGCOAI>2.3.CO;2\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.epsl.2010.08.012\n",
            "Arquivo .bib salvo para o DOI 10.1190/1.1605081\n",
            "Arquivo .bib salvo para o DOI 10.2113/2022/2103213\n",
            "Arquivo .bib salvo para o DOI 10.1016/0012-821X(87)90007-0\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.tecto.2015.07.003\n",
            "Arquivo .bib salvo para o DOI 10.1144/GSL.SP.1992.068.01.14\n",
            "Arquivo .bib salvo para o DOI 10.1093/petrology/Special_Volume.1.205\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.jsames.2020.102710\n",
            "Arquivo .bib salvo para o DOI 10.1038/ncomms8799\n",
            "Arquivo .bib salvo para o DOI 10.1190/sbgf2013-149\n",
            "Arquivo .bib salvo para o DOI 10.1029/2017GL076691\n",
            "Arquivo .bib salvo para o DOI 10.1029/2007JB005374\n",
            "Arquivo .bib salvo para o DOI 10.1306/13722321MSB.9.1853\n",
            "Arquivo .bib salvo para o ISBN 978-0-632-04929-5\n",
            "Arquivo .bib salvo para o ISBN 978-85-8260-135-8\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.gloplacha.2021.103501\n",
            "Arquivo .bib salvo para o DOI 10.56577/FFC-26.169\n",
            "Arquivo .bib salvo para o DOI 10.1130/0091-7613(1978)6<236:DAGOFD>2.0.CO;2\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.tecto.2023.230004\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.jvolgeores.2016.12.003\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.gsf.2022.101479\n",
            "Arquivo .bib salvo para o DOI 10.18814/epiiugs/2005/v28i1/002\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.gloplacha.2021.103689\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.jsames.2020.103043\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.marpetgeo.2016.06.004\n",
            "Arquivo .bib salvo para o DOI 10.1007/978-94-007-6644-0_105-1\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.gr.2014.08.006\n",
            "Arquivo .bib salvo para o DOI 10.25249/0375-7536.1998473484\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.earscirev.2009.08.001\n",
            "Arquivo .bib salvo para o DOI 10.3997/2214-4609-pdb.217.374a\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.jsames.2023.104435\n",
            "Arquivo .bib salvo para o DOI 10.1590/2317-4889202020200003\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.lithos.2017.11.001\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.gr.2012.05.016\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.jsames.2018.06.023\n",
            "Arquivo .bib salvo para o DOI 10.1007/978-3-319-68920-3_8\n",
            "Arquivo .bib salvo para o DOI 10.1002/2013JB010626\n",
            "Arquivo .bib salvo para o DOI 10.1007/BF00301125\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.marpetgeo.2013.02.002\n",
            "Arquivo .bib salvo para o DOI 10.1590/2317-4889201820170110\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.jsames.2018.12.006\n",
            "Arquivo .bib salvo para o DOI 10.1007/978-3-319-68920-3_10\n",
            "Arquivo .bib salvo para o DOI 10.1029/2000JB900080\n",
            "Arquivo .bib salvo para o DOI 10.5016/GEOCIENCIAS.V37I3.12172\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.jsames.2013.04.004\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.lithos.2020.105519\n",
            "Arquivo .bib salvo para o DOI 10.3809/jvirtex.2002.00046\n",
            "Arquivo .bib salvo para o DOI 10.5281/zenodo.5460860\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.marpetgeo.2013.10.015\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.jseaes.2012.11.047\n",
            "Arquivo .bib salvo para o DOI 10.18814/epiiugs/2001/v24i4/004\n",
            "Arquivo .bib salvo para o DOI 10.1130/G30510.1\n",
            "Arquivo .bib salvo para o DOI 10.1785/0220120032\n",
            "Arquivo .bib salvo para o DOI 10.1007/978-3-319-01715-0_10\n",
            "Arquivo .bib salvo para o DOI 10.1038/ngeo708\n",
            "Arquivo .bib salvo para o DOI 10.1016/j.tecto.2017.10.004\n",
            "Arquivo .bib salvo para o DOI 10.2475/10.2010.03\n",
            "Arquivo .bib salvo para o DOI 10.14682/2016TEMSA\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def read_doi_csv(csv_file):\n",
        "  df = pd.read_csv(csv_file)\n",
        "  doi_list = df['doi_and_isbn'].tolist()\n",
        "  return doi_list\n",
        "\n",
        "csv_file = list(uploaded.keys())[0]\n",
        "doi_list = read_doi_csv(csv_file)\n",
        "bibtex_list, log_list = list(), list()\n",
        "\n",
        "for item in doi_list:\n",
        "  item = str(item)\n",
        "  try:\n",
        "    if item.startswith('10.'):\n",
        "      bib_dict, log = doi2bibfile_quotes(item)\n",
        "      bibtex_list.append(bib_dict)\n",
        "    else:\n",
        "      bib_dict, log = isbn2bibfile_quotes(item)\n",
        "      bibtex_list.append(bib_dict)\n",
        "  except Exception as e:\n",
        "    print(f'*** Exception para o código {item}:{str(e)}')\n",
        "    log_list.append([item,  str(e)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlE3cea_KdKf"
      },
      "outputs": [],
      "source": [
        "#Ordenar os registros em bibtex_list por ordem alfabética e ano\n",
        "# bibtex_list.sort(key=lambda x: (x['author'].split(',')[0].split()[0], x['year']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Salvar arquivos .bib gerados"
      ],
      "metadata": {
        "id": "NY6GxKeDNA_J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "UF-xc-GEzzj4",
        "outputId": "cec68342-e543-4d58-e5a8-4c057730ec06"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e428577c-ceac-4573-8464-d9905619e9cb\", \"content_files.zip\", 7169037)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# # Salvar um arquivo .zip dos arquivos\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"/content/content_files\", 'zip', '/content/')\n",
        "files.download('content_files.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wygYSnOpm6zH"
      },
      "source": [
        "#Criar lista de referencias (saída em HTML)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMRHbyBAnqcw"
      },
      "source": [
        "##Importações e instalações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV0gjYRCnv5e",
        "outputId": "c91bba46-f8e5-4edd-d32b-8bd6a00e8d4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.4/561.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.9/179.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bibtexparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pybtex -q\n",
        "!pip install citeproc-py -q\n",
        "!pip install --no-cache-dir --force-reinstall git+https://github.com/sciunto-org/python-bibtexparser@main -q\n",
        "#instalar estilos\n",
        "!pip install citeproc-py citeproc-py-styles -q\n",
        "# !pip install gitpython -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnQzRMQHn5zB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from citeproc.source.bibtex import BibTeX\n",
        "from citeproc import CitationStylesStyle, CitationStylesBibliography, formatter\n",
        "from citeproc_styles import get_style_filepath\n",
        "from citeproc import Citation, CitationItem\n",
        "from google.colab import files\n",
        "import io\n",
        "# import git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNUldPI_oifY"
      },
      "source": [
        "###Formatação do texto no estilo da revista\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXBS-HjEp3D2"
      },
      "source": [
        "\n",
        "Verifique se a revista possui um modelo .CSL (Citation Style Language) cadastrado no repositorio (https://github.com/citation-style-language/styles) da biblioteca citeproc-py-styles https://pypi.org/project/citeproc-py-styles/ .\n",
        "Insira o nome na variável abaixo, como cadastrado no repositório."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2T77qoco0TJ"
      },
      "outputs": [],
      "source": [
        "# Estilo pretendido - revista\n",
        "csl_model = \"journal-of-geophysical-research-solid-earth\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrfA5Ra3Lii6"
      },
      "source": [
        "###Obter a lista de referencias a partir dos arquivos .bib na pasta /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhZYJg7YoF-2",
        "outputId": "5b2bef7e-d4c0-436a-9d81-f883aabaa82b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erro ao ler dados do arquivo. Artemieva2011-07-28book.bib\n",
            "Erro ao ler dados do arquivo. cordani1984.bib\n",
            "Erro ao ler dados do arquivo. Kearey2002-04-26book.bib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/citeproc/source/bibtex/bibtex.py:89: UserWarning: Unsupported BibTeX field 'organization'\n",
            "  warn(\"Unsupported BibTeX field '{}'\".format(field))\n",
            "/usr/local/lib/python3.10/dist-packages/citeproc/source/bibtex/bibtex.py:89: UserWarning: Unsupported BibTeX field 'institution'\n",
            "  warn(\"Unsupported BibTeX field '{}'\".format(field))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'de_morisson_valeriano_2016': Reference(de_morisson_valeriano_2016)},\n",
              " {'kir_ly_2021': Reference(kir_ly_2021)},\n",
              " {'dragone_2017': Reference(dragone_2017)},\n",
              " {'eyles_1993': Reference(eyles_1993)},\n",
              " {'schellart_2002': Reference(schellart_2002)},\n",
              " {'lithgow_bertelloni_2014': Reference(lithgow_bertelloni_2014)},\n",
              " {'evain_2015': Reference(evain_2015)},\n",
              " {'zalan1990bacia': Reference(zalan1990bacia)},\n",
              " {'szatmari_2016': Reference(szatmari_2016)},\n",
              " {'arena_2016': Reference(arena_2016)},\n",
              " {'faccenna_2010': Reference(faccenna_2010)},\n",
              " {'angiboust_2012': Reference(angiboust_2012)},\n",
              " {'manatschal_2015': Reference(manatschal_2015)},\n",
              " {'moulin_2010': Reference(moulin_2010)},\n",
              " {'juli__2008': Reference(juli__2008)},\n",
              " {'cordani2010rio': Reference(cordani2010rio)},\n",
              " {'pinto_2019': Reference(pinto_2019)},\n",
              " {'affonso_2021': Reference(affonso_2021)},\n",
              " {'lei_2023': Reference(lei_2023)},\n",
              " {'mohriak_2023': Reference(mohriak_2023)},\n",
              " {'zalan2011santos': Reference(zalan2011santos)},\n",
              " {'licht2015role': Reference(licht2015role)},\n",
              " {'rocha_j_nior_2013': Reference(rocha_j_nior_2013)},\n",
              " {'rocha_j_nior_2020': Reference(rocha_j_nior_2020)},\n",
              " {'chaves_2016': Reference(chaves_2016)},\n",
              " {'arag_o_2022': Reference(arag_o_2022)},\n",
              " {'ueipass_mohriak_2001': Reference(ueipass_mohriak_2001)},\n",
              " {'cerva_alves_2021': Reference(cerva_alves_2021)},\n",
              " {'ferreira1981guapiara': Reference(ferreira1981guapiara)},\n",
              " {'passarelli_2018': Reference(passarelli_2018)},\n",
              " {'dewey_1970': Reference(dewey_1970)},\n",
              " {'umberto_victor_lêda_2019': Reference(umberto_victor_lêda_2019)},\n",
              " {'iglesias_2013': Reference(iglesias_2013)},\n",
              " {'trabant_2012': Reference(trabant_2012)},\n",
              " {'https://doi.org/10.5281/zenodo.5460860': Reference(https://doi.org/10.5281/zenodo.5460860)},\n",
              " {'beccaluva_2020': Reference(beccaluva_2020)},\n",
              " {'peyerl_2018': Reference(peyerl_2018)},\n",
              " {'johansson_2018': Reference(johansson_2018)},\n",
              " {'karner_2021': Reference(karner_2021)},\n",
              " {'natali_2018': Reference(natali_2018)},\n",
              " {'bologna_2013': Reference(bologna_2013)},\n",
              " {'souza2022reatecap6': Reference(souza2022reatecap6)},\n",
              " {'bizzi_1995': Reference(bizzi_1995)},\n",
              " {'stica_2014': Reference(stica_2014)},\n",
              " {'milani2020embasamento': Reference(milani2020embasamento)},\n",
              " {'lobo2006magma': Reference(lobo2006magma)},\n",
              " {'fairhead_2003': Reference(fairhead_2003)},\n",
              " {'dziewonski_1981': Reference(dziewonski_1981)},\n",
              " {'licht_2018': Reference(licht_2018)},\n",
              " {'faleiros_2022': Reference(faleiros_2022)},\n",
              " {'hall_2015': Reference(hall_2015)},\n",
              " {'hawkesworth_1988': Reference(hawkesworth_1988)},\n",
              " {'almeida_2021': Reference(almeida_2021)},\n",
              " {'pasyanos_2014': Reference(pasyanos_2014)},\n",
              " {'christensen_1996': Reference(christensen_1996)},\n",
              " {'basei_2009': Reference(basei_2009)},\n",
              " {'laske2013crust1': Reference(laske2013crust1)},\n",
              " {'ca_n_tapia_2018': Reference(ca_n_tapia_2018)},\n",
              " {'heilbron_2020': Reference(heilbron_2020)},\n",
              " {'peate_1992': Reference(peate_1992)},\n",
              " {'fodor_1987': Reference(fodor_1987)},\n",
              " {'ballmer_2015': Reference(ballmer_2015)},\n",
              " {'padilha_2013': Reference(padilha_2013)},\n",
              " {'barnes_2018': Reference(barnes_2018)},\n",
              " {'hawkesworth_1992': Reference(hawkesworth_1992)},\n",
              " {'mac_do_filho_2023': Reference(mac_do_filho_2023)},\n",
              " {'van_der_meer_2018': Reference(van_der_meer_2018)},\n",
              " {'hoernle_2015': Reference(hoernle_2015)},\n",
              " {'tassinari_2001': Reference(tassinari_2001)},\n",
              " {'milani_1998': Reference(milani_1998)},\n",
              " {'tang_2013': Reference(tang_2013)},\n",
              " {'rios_2018': Reference(rios_2018)},\n",
              " {'matenco_2022': Reference(matenco_2022)},\n",
              " {'amaru2007book': Reference(amaru2007book)},\n",
              " {'marques2004magmatismo': Reference(marques2004magmatismo)},\n",
              " {'tohver_2010': Reference(tohver_2010)},\n",
              " {'comin_chiaramonti_2007': Reference(comin_chiaramonti_2007)},\n",
              " {'lamarre_1978': Reference(lamarre_1978)},\n",
              " {'peron_pinvidic_2013': Reference(peron_pinvidic_2013)},\n",
              " {'van_der_meer_2009': Reference(van_der_meer_2009)},\n",
              " {'lamarre_1975': Reference(lamarre_1975)},\n",
              " {'philipp_2018': Reference(philipp_2018)},\n",
              " {'panetto_2018': Reference(panetto_2018)},\n",
              " {'frank2007contaminacao': Reference(frank2007contaminacao)},\n",
              " {'windley_2010': Reference(windley_2010)},\n",
              " {'pysklywec_2000': Reference(pysklywec_2000)},\n",
              " {'moraes_2020': Reference(moraes_2020)},\n",
              " {'kearey2014book': Reference(kearey2014book)},\n",
              " {'silva_2021': Reference(silva_2021)},\n",
              " {'mantovani_2005': Reference(mantovani_2005)}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Abrir arquivos BibTeX da pasta\n",
        "folder_path = \"/content/\"\n",
        "entries = []\n",
        "biblist = []\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.bib'):\n",
        "      try:\n",
        "          file_path = os.path.join(folder_path, filename)\n",
        "          with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            bib_src = BibTeX(file)\n",
        "            biblist.append(bib_src)  # lista de dicionários\n",
        "      except:\n",
        "          print(\"Erro ao ler dados do arquivo.\", filename)\n",
        "biblist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k37B59cUqXnc"
      },
      "source": [
        "###Formatar e salvar arquivo de saída"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6QdVIA6-nDE3",
        "outputId": "b3fe5402-5ef7-49b8-b81f-01e9e306bf4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adicionado - de Morisson Valeriano, C..  (2016). The Southern Brasília Belt (pp. 189–203). Springer International Publishing. https://doi.org/10.1007/978-3-319-01715-0_10\n",
            "Adicionado - Király, Á., Funiciello, F., Capitanio, F. A., &amp; Faccenna, C..  (2021). Dynamic interactions between subduction zones. <i>Global and Planetary Change</i>, <i>202</i>, 103501. https://doi.org/10.1016/j.gloplacha.2021.103501\n",
            "Adicionado - Dragone, G. N., Ussami, N., Gimenez, M. E., Lince Klinger, F. G., &amp; Chaves, C. A. M..  (2017). Western Paraná suture/shear zone and the limits of Rio Apa, Rio Tebicuary and Rio de la Plata cratons from gravity data. <i>Precambrian Research</i>, <i>291</i>, 162–177. https://doi.org/10.1016/j.precamres.2017.01.029\n",
            "Adicionado - Eyles, N., &amp; Eyles, C. H..  (1993). Glacial geologic confirmation of an intraplate boundary, in the Paraná basin of Brazil. <i>Geology</i>, <i>21</i>(5), 459. https://doi.org/10.1130/0091-7613(1993)021<0459:GGCOAI>2.3.CO;2\n",
            "Adicionado - Schellart, W. P., Lister, G. S., &amp; Jessell, M. W..  (2002). Analogue modelling of asymmetrical back-arc extension. <i>Journal of the Virtual Explorer</i>, <i>7</i>. https://doi.org/10.3809/jvirtex.2002.00046\n",
            "Adicionado - Lithgow-Bertelloni, C..  (2014). Driving Forces: Slab Pull, Ridge Push (pp. 1–6). Springer Netherlands. https://doi.org/10.1007/978-94-007-6644-0_105-1\n",
            "Adicionado - Evain, M., Afilhado, A., Rigoti, C., Loureiro, A., Alves, D., Klingelhoefer, F., et al..  (2015). Deep structure of the Santos Basin‐São Paulo Plateau System, SE Brazil. <i>Journal of Geophysical Research: Solid Earth</i>, <i>120</i>(8), 5401–5431. https://doi.org/10.1002/2014JB011561\n",
            "Adicionado - Zalán, P. V., Wolff, S. J. C. J., Conceição, J. C. de J., Marques, A., Astolfi, M. A. M., Vieira, I. S., et al..  (1990). Bacia do Paraná. In <i>Origem e evolução das bacias sedimentares</i> (pp. 135–168). Petrobras Rio de Janeiro.\n",
            "Adicionado - Szatmari, P., &amp; Milani, E. J..  (2016). Tectonic control of the oil-rich large igneous-carbonate-salt province of the South Atlantic rift. <i>Marine and Petroleum Geology</i>, <i>77</i>, 567–596. https://doi.org/10.1016/j.marpetgeo.2016.06.004\n",
            "Adicionado - Arena, K. R., Hartmann, L. A., &amp; Lana, C..  (2016). Evolution of Neoproterozoic ophiolites from the southern Brasiliano Orogen revealed by zircon U-Pb-Hf isotopes and geochemistry. <i>Precambrian Research</i>, <i>285</i>, 299–314. https://doi.org/10.1016/j.precamres.2016.09.014\n",
            "Adicionado - Faccenna, C., Becker, T. W., Lallemand, S., Lagabrielle, Y., Funiciello, F., &amp; Piromallo, C..  (2010). Subduction-triggered magmatic pulses: A new class of plumes?. <i>Earth and Planetary Science Letters</i>, <i>299</i>(1–2), 54–68. https://doi.org/10.1016/j.epsl.2010.08.012\n",
            "Adicionado - Angiboust, S., Wolf, S., Burov, E., Agard, P., &amp; Yamato, P..  (2012). Effect of fluid circulation on subduction interface tectonic processes: Insights from thermo-mechanical numerical modelling. <i>Earth and Planetary Science Letters</i>, <i>357–358</i>, 238–248. https://doi.org/10.1016/j.epsl.2012.09.012\n",
            "Adicionado - Manatschal, G., Lavier, L., &amp; Chenin, P..  (2015). The role of inheritance in structuring hyperextended rift systems: Some considerations based on observations and numerical modeling. <i>Gondwana Research</i>, <i>27</i>(1), 140–164. https://doi.org/10.1016/j.gr.2014.08.006\n",
            "Adicionado - Moulin, M., Aslanian, D., &amp; Unternehr, P..  (2010). A new starting point for the South and Equatorial Atlantic Ocean. <i>Earth-science Reviews</i>, <i>98</i>(1–2), 1–37. https://doi.org/10.1016/j.earscirev.2009.08.001\n",
            "Adicionado - Julià, J., Assumpção, M., &amp; Rocha, M. P..  (2008). Deep crustal structure of the Paraná Basin from receiver functions and Rayleigh‐wave dispersion: Evidence for a fragmented cratonic root. <i>Journal of Geophysical Research: Solid Earth</i>, <i>113</i>(B8). https://doi.org/10.1029/2007JB005374\n",
            "Adicionado - Cordani, U. G., Teixeira, W., Tassinari, C. C., Coutinho, J. M., &amp; Ruiz, A. S..  (2010). The Rio Apa Craton in Mato Grosso do Sul (Brazil) and northern Paraguay: geochronological evolution, correlations and tectonic implications for Rodinia and Gondwana. <i>American Journal of Science</i>, <i>310</i>(9), 981–1023.\n",
            "Adicionado - Pinto, M. L., &amp; Vidotti, R. M..  (2019). Tectonic framework of the Paraná basin unveiled from gravity and magnetic data. <i>Journal of South American Earth Sciences</i>, <i>90</i>, 216–232. https://doi.org/10.1016/j.jsames.2018.12.006\n",
            "Adicionado - Affonso, G. M. P. C., Rocha, M. P., Costa, I. S. L., Assumpção, M., Fuck, R. A., Albuquerque, D. F., et al..  (2021). Lithospheric Architecture of the Paranapanema Block and Adjacent Nuclei Using Multiple‐Frequency P‐Wave Seismic Tomography. <i>Journal of Geophysical Research: Solid Earth</i>, <i>126</i>(4). https://doi.org/10.1029/2020JB021183\n",
            "Adicionado - Lei, Z., &amp; Davies, J. H..  (2023). Progressive weakening within the overriding plate during dual inward dipping subduction. <i>Tectonophysics</i>, <i>863</i>, 230004. https://doi.org/10.1016/j.tecto.2023.230004\n",
            "Adicionado - Mohriak, W. U., &amp; Szameitat, L..  (2023). The anomalous magmatism in the southern part of the Santos basin, and the non-continuous salt layer over Abimael Ridge. <i>Journal of South American Earth Sciences</i>, <i>128</i>, 104435. https://doi.org/10.1016/j.jsames.2023.104435\n",
            "***Exception: Erro ao tratar informações de CitationItem(zalan2011santos)\n",
            "Adicionado - Licht, O. A., Gomes, A. S., &amp; Vasconcellos, E. M..  (2015). The role played by fluorine in the Serra Geral volcanics, Paraná Igneous Province: A first glance. In <i>Proc.... XV Congresso Brasileiro de Geoquímica</i>.\n",
            "Adicionado - Rocha-Júnior, E. R. V., Marques, L. S., Babinski, M., Nardy, A. J. R., Figueiredo, A. M. G., &amp; Machado, F. B..  (2013). Sr–Nd–Pb isotopic constraints on the nature of the mantle sources involved in the genesis of the high-Ti tholeiites from northern Paraná Continental Flood Basalts (Brazil). <i>Journal of South American Earth Sciences</i>, <i>46</i>, 9–25. https://doi.org/10.1016/j.jsames.2013.04.004\n",
            "Adicionado - Rocha-Júnior, E. R. V., Marques, L. S., Babinski, M., Machado, F. B., Petronilho, L. A., &amp; Nardy, A. J. R..  (2020). A telltale signature of Archean lithospheric mantle in the Paraná continental flood basalts genesis. <i>Lithos</i>, <i>364–365</i>, 105519. https://doi.org/10.1016/j.lithos.2020.105519\n",
            "Adicionado - Chaves, C., Ussami, N., &amp; Ritsema, J..  (2016). Density and P‐wave velocity structure beneath the Paraná Magmatic Province: Refertilization of an ancient lithospheric mantle. <i>Geochemistry, Geophysics, Geosystems</i>, <i>17</i>(8), 3054–3074. https://doi.org/10.1002/2016GC006369\n",
            "Adicionado - Aragão, M. A. N. F. de ., Szameitat, L. S. A., Figueiredo, A. M. F. de ., Heilbron, M., &amp; Manatschal, G..  (2022). Architectural elements, geometry, and magmatism of the Sub-Saharan Western African passive margin basins: Seismic and gravity data integration. <i>Journal of South American Earth Sciences</i>, <i>120</i>, 104062. https://doi.org/10.1016/j.jsames.2022.104062\n",
            "Adicionado - Ueipass Mohriak, W..  (2001). South Atlantic Ocean Salt Tectonics, Volcanic Centers, Fracture Zones And Their Relationship With The Origin And Evolution Of The South Atlantic Ocean: Geophysical Evidence In The Brazilian And West African Margins.. European Association of Geoscientists & Engineers. https://doi.org/10.3997/2214-4609-pdb.217.374a\n",
            "Adicionado - Cerva-Alves, T., Hartmann, L. A., Queiroga, G. N., Lana, C., Castro, M. P., Maciel, L. A. C., &amp; Remus, M. V. D..  (2021). Metamorphic evolution of the juvenile Serrinha forearc basin in the southern Brasiliano Orogen. <i>Precambrian Research</i>, <i>365</i>, 106394. https://doi.org/10.1016/j.precamres.2021.106394\n",
            "Adicionado - Ferreira, F., Moraes, R., Ferrari, M., &amp; Vianna, R..  (1981). Contribuição ao estudo do Alinhamento Estrutural de Guapiara. <i>Simpósio Regional De Geologia</i>, <i>3</i>(1981), 226–240.\n",
            "Adicionado - Passarelli, C. R., Basei, M. A. S., Siga, O., &amp; Harara, O. M. M..  (2018). The Luis Alves and Curitiba Terranes: Continental Fragments in the Adamastor Ocean (pp. 189–215). Springer International Publishing. https://doi.org/10.1007/978-3-319-68920-3_8\n",
            "Adicionado - Dewey, J. F., &amp; Bird, J. M..  (1970). Mountain belts and the new global tectonics. <i>Journal of Geophysical Research</i>, <i>75</i>(14), 2625–2647. https://doi.org/10.1029/JB075i014p02625\n",
            "Adicionado - Umberto, C., Victor, R., &amp; Lêda, F..  (2019). <i>Tectonic Map of South America at 1:5 900 000 scale</i>. Commission for the Geological Map of the World (CGMW). https://doi.org/10.14682/2016TEMSA\n",
            "Adicionado - Iglesias, M. L., Rolim, S. B. A., Laukamp, C., &amp; Binotto, R. B..  (2013). Thermal Infrared Spectroscopy and Geochemical Analyses of Volcanic Rocks from the Paraná Basin (Brazil). Brazilian Geophysical Society. https://doi.org/10.1190/sbgf2013-149\n",
            "Adicionado - Trabant, C., Hutko, A. R., Bahavar, M., Karstens, R., Ahern, T., &amp; Aster, R..  (2012). Data Products at the IRIS DMC: Stepping Stones for Research and Other Applications. <i>Seismological Research Letters</i>, <i>83</i>(5), 846–854. https://doi.org/10.1785/0220120032\n",
            "Adicionado - Scotese, C. R., &amp; Wright, N. M..  (2018). PALEOMAP Paleodigital Elevation Models (PaleoDEMS) for the Phanerozoic. Zenodo. https://doi.org/10.5281/zenodo.5460860\n",
            "Adicionado - Beccaluva, L., Bianchini, G., Natali, C., &amp; Siena, F..  (2020). Plume-related Paranà-Etendeka igneous province: An evolution from plateau to continental rifting and breakup. <i>Lithos</i>, <i>362–363</i>, 105484. https://doi.org/10.1016/j.lithos.2020.105484\n",
            "Adicionado - Peyerl, W. R. L., Salamuni, E., Sanches, E., Nascimento, E. R. do ., Santos, J. M., Gimenez, V. B., et al..  (2018). Reativation of Taxaquara Fault and its morphotectonic influence on the evolution of Jordão River catchment, Paraná, Brasil. <i>Brazilian Journal of Geology</i>, <i>48</i>(3), 553–573. https://doi.org/10.1590/2317-4889201820170110\n",
            "Adicionado - Johansson, L., Zahirovic, S., &amp; Müller, R. D..  (2018). The Interplay Between the Eruption and Weathering of Large Igneous Provinces and the Deep‐Time Carbon Cycle. <i>Geophysical Research Letters</i>, <i>45</i>(11), 5380–5389. https://doi.org/10.1029/2017GL076691\n",
            "Adicionado - Karner, G. D., Johnson, C., Shoffner, J., Lawson, M., Sullivan, M., Sitgreaves, J., et al..  (2021). Chapter 9: Tectono-Magmatic Development of the Santos and Campos Basins, Offshore Brazil (pp. 215–256). AAPG. https://doi.org/10.1306/13722321MSB.9.1853\n",
            "Adicionado - Natali, C., Beccaluva, L., Bianchini, G., &amp; Siena, F..  (2018). Coexistence of alkaline-carbonatite complexes and high-MgO CFB in the Paranà-Etendeka province: Insights on plume-lithosphere interactions in the Gondwana realm. <i>Lithos</i>, <i>296–299</i>, 54–66. https://doi.org/10.1016/j.lithos.2017.11.001\n",
            "Adicionado - Bologna, M. S., Nunes, H. O., Padilha, A. L., Vitorello, Í., &amp; Pádua, M. B..  (2013). Anomalous electrical structure in the northwestern Paraná Basin, Brazil, observed with broadband magnetotellurics. <i>Journal of South American Earth Sciences</i>, <i>42</i>, 74–82. https://doi.org/10.1016/j.jsames.2012.07.006\n",
            "Adicionado - Souza-Filho, L. S. A., O. A.; Szameitat.  (2022). <i>Contribuição aos estudos geofísicos da Bacias Interiores-Bacia do Paraná</i> (p. 156). Rio de Janeiro, Brazil.\n",
            "Adicionado - Bizzi, L. a ., De Wit, M. J., Smith, C. B., Mcdonald, I., &amp; R.A., A..  (1995). Heterogeneous enriched mantle materials and dupal-type magmatism along the SW margin of the São Francisco craton, Brazil. <i>Journal of Geodynamics</i>, <i>20</i>(4), 469–491. https://doi.org/10.1016/0264-3707(95)00028-8\n",
            "Adicionado - Stica, J. M., Zalán, P. V., &amp; Ferrari, A. L..  (2014). The evolution of rifting on the volcanic margin of the Pelotas Basin and the contextualization of the Paraná–Etendeka LIP in the separation of Gondwana in the South Atlantic. <i>Marine and Petroleum Geology</i>, <i>50</i>, 1–21. https://doi.org/10.1016/j.marpetgeo.2013.10.015\n",
            "Adicionado - Milani, E. J., &amp; Szatmari, P..  (2020). Influência do embasamento na evolução de bacias sedimentares: A contribuição de Umberto Giuseppe Cordani e do grupo de Geocronologia e Tectônica da USP para as atividades exploratórias da Petrobras. <i>Geocronologia E Evolução Tectônica Do Continente Sul-americano: A Contribuição De Umberto Giuseppe Cordani</i>, 357–391.\n",
            "Adicionado - Lobo, J. T., Valente, S. C., Szatmari, P., &amp; Duarte, B. P..  (2006). Tipos de fontes associadas às suítes basálticas de Campos e de Pelotas (Sul-Sudeste) e modelos geodinâmicos de ruptura do Gondwana ocidental. <i>Boletim De Geociências Da Petrobras</i>, <i>12</i>(2), 271–287.\n",
            "Adicionado - Fairhead, J. D., &amp; Maus, S..  (2003). CHAMP satellite and terrestrial magnetic data help define the tectonic model for South America and resolve the lingering problem of the pre-break-up fit of the South Atlantic Ocean. <i>The Leading Edge</i>, <i>22</i>(8), 779–783. https://doi.org/10.1190/1.1605081\n",
            "Adicionado - Dziewonski, A. M., &amp; Anderson, D. L..  (1981). Preliminary reference Earth model. <i>Physics of the Earth and Planetary Interiors</i>, <i>25</i>(4), 297–356. https://doi.org/10.1016/0031-9201(81)90046-7\n",
            "Adicionado - Licht, O. A. B..  (2018). A revised chemo-chrono-stratigraphic 4-D model for the extrusive rocks of the Paraná Igneous Province. <i>Journal of Volcanology and Geothermal Research</i>, <i>355</i>, 32–54. https://doi.org/10.1016/j.jvolgeores.2016.12.003\n",
            "Adicionado - Faleiros, F. M., Ribeiro, B. V., Campanha, G. A. C., Cawood, P. A., Cabrita, D. I. G., Yogi, M. T. A. G., et al..  (2022). Strain Partitioning along Terrane Bounding and Intraterrane Shear Zones: Constraints from a Long-Lived Transpressional System in West Gondwana (Ribeira Belt, Brazil). <i>Lithosphere</i>, <i>2021</i>(Special 6). https://doi.org/10.2113/2022/2103213\n",
            "Adicionado - Hall, R., &amp; Spakman, W..  (2015). Mantle structure and tectonic history of SE Asia. <i>Tectonophysics</i>, <i>658</i>, 14–45. https://doi.org/10.1016/j.tecto.2015.07.003\n",
            "Adicionado - Hawkesworth, C., Mantovani, M., &amp; Peate, D..  (1988). Lithosphere Remobilization during Parana CFB Magmatism. <i>Journal of Petrology</i>, <i>Special_Volume</i>(1), 205–223. https://doi.org/10.1093/petrology/Special_Volume.1.205\n",
            "Adicionado - Almeida, J., Heilbron, M., Guedes, E., Neubauer, F., Manfred, B., Klausen, M. B., et al..  (2021). Pre-to-syn-rift tholeiitic magmatism in a transtensive hyperextended continental margin: Onshore and offshore magmatism of the Campos Basin, SE Brazil. <i>Journal of South American Earth Sciences</i>, <i>108</i>, 103218. https://doi.org/10.1016/j.jsames.2021.103218\n",
            "Adicionado - Pasyanos, M. E., Masters, T. G., Laske, G., &amp; Ma, Z..  (2014). LITHO1.0: An updated crust and lithospheric model of the Earth. <i>Journal of Geophysical Research: Solid Earth</i>, <i>119</i>(3), 2153–2173. https://doi.org/10.1002/2013JB010626\n",
            "Adicionado - Christensen, U. R..  (1996). The influence of trench migration on slab penetration into the lower mantle. <i>Earth and Planetary Science Letters</i>, <i>140</i>(1–4), 27–39. https://doi.org/10.1016/0012-821X(96)00023-4\n",
            "Adicionado - Basei, M. A. S., Nutman, A., Siga, O., Passarelli, C. R., &amp; Drukas, C. O..  (2009). Chapter 7.2 The Evolution and Tectonic Setting of the Luis Alves Microplate of Southeastern Brazil: An Exotic Terrane during the Assembly of Western Gondwana (pp. 273–291). Elsevier. https://doi.org/10.1016/S0166-2635(09)01620-X\n",
            "Adicionado - Laske, G., Masters, G., Ma, Z., &amp; Pasyanos, M..  (2013). Update on CRUST1.0 - A 1-degree global model of Earth's crust. <i>Abstract EGU2013-2658 Presented at 2013 Geophys. Res. Abstracts 15</i>, <i>15</i>, 2658.\n",
            "Adicionado - Cañón-Tapia, E..  (2018). The Paraná-Etendeka Continental Flood Basalt Province: A historical perspective of current knowledge and future research trends. <i>Journal of Volcanology and Geothermal Research</i>, <i>355</i>, 287–303. https://doi.org/10.1016/j.jvolgeores.2017.11.011\n",
            "Adicionado - Heilbron, M., de Morisson Valeriano, C., Peixoto, C., Tupinambá, M., Neubauer, F., Dussin, I., et al..  (2020). Neoproterozoic magmatic arc systems of the central Ribeira belt, SE-Brazil, in the context of the West-Gondwana pre-collisional history: A review. <i>Journal of South American Earth Sciences</i>, <i>103</i>, 102710. https://doi.org/10.1016/j.jsames.2020.102710\n",
            "Adicionado - Peate, D. W., Hawkesworth, C. J., &amp; Mantovani, M. S. M..  (1992). Chemical stratigraphy of the Paran� lavas (South America): classification of magma types and their spatial distribution. <i>Bulletin of Volcanology</i>, <i>55</i>(1–2), 119–139. https://doi.org/10.1007/BF00301125\n",
            "Adicionado - Fodor, R. V..  (1987). Low- and high-TiO2 flood basalts of southern Brazil: origin from picritic parentage and a common mantle source. <i>Earth and Planetary Science Letters</i>, <i>84</i>(4), 423–430. https://doi.org/10.1016/0012-821X(87)90007-0\n",
            "Adicionado - Ballmer, M. D., Schmerr, N. C., Nakagawa, T., &amp; Ritsema, J..  (2015). Compositional mantle layering revealed by slab stagnation at  1000-km depth. <i>Science Advances</i>, <i>1</i>(11). https://doi.org/10.1126/sciadv.1500815\n",
            "Adicionado - Padilha, A. L., Vitorello, I., &amp; Pádua, M. B..  (2013). Deep conductivity structure beneath the northern Brasília belt, central Brazil: Evidence for a Neoproterozoic arc-continent collision. <i>Gondwana Research</i>, <i>23</i>(2), 748–758. https://doi.org/10.1016/j.gr.2012.05.016\n",
            "Adicionado - Barnes, J. D., Manning, C. E., Scambelluri, M., &amp; Selverstone, J..  (2018). The Behavior of Halogens During Subduction-Zone Processes (pp. 545–590). Springer International Publishing. https://doi.org/10.1007/978-3-319-61667-4_8\n",
            "Adicionado - Hawkesworth, C. J., Gallagher, K., Kelley, S., Mantovani, M., Peate, D. W., Regelous, M., &amp; Rogers, N. W..  (1992). Paraná magmatism and the opening of the South Atlantic. <i>Geological Society, London, Special Publications</i>, <i>68</i>(1), 221–240. https://doi.org/10.1144/GSL.SP.1992.068.01.14\n",
            "Adicionado - Macêdo Filho, A. A., Hollanda, M. H. B. M., Fraser, S., Oliveira, A. L., Melo, A. C. C., &amp; Dantas, A. R..  (2023). Correlations among large igneous provinces related to the West Gondwana breakup: A geochemical database reappraisal of Early Cretaceous plumbing systems. <i>Geoscience Frontiers</i>, <i>14</i>(1), 101479. https://doi.org/10.1016/j.gsf.2022.101479\n",
            "Adicionado - van der Meer, D. G., van Hinsbergen, D. J. J., &amp; Spakman, W..  (2018). Atlas of the underworld: Slab remnants in the mantle, their sinking history, and a new outlook on lower mantle viscosity. <i>Tectonophysics</i>, <i>723</i>, 309–448. https://doi.org/10.1016/j.tecto.2017.10.004\n",
            "Adicionado - Hoernle, K., Rohde, J., Hauff, F., Garbe-Schönberg, D., Homrighausen, S., Werner, R., &amp; Morgan, J. P..  (2015). How and when plume zonation appeared during the 132 Myr evolution of the Tristan Hotspot. <i>Nature Communications</i>, <i>6</i>(1). https://doi.org/10.1038/ncomms8799\n",
            "Adicionado - Tassinari, C. C. G., Munhá, J. M. U., Ribeiro, A., &amp; Correia, C. T..  (2001). Neoproterozoic oceans in the Ribeira Belt (southeastern Brazil): The Pirapora do Bom Jesus ophiolitic complex. <i>Episodes</i>, <i>24</i>(4), 245–251. https://doi.org/10.18814/epiiugs/2001/v24i4/004\n",
            "Adicionado - MILANI, E. J., &amp; RAMOS, V. A..  (1998). OROGENIAS PALEOZÓICAS NO DOMÍNIO SUL-OCIDENTAL DO GONDWANA E OS CICLOS DE SUBSIDÊNCIA DA BACIA DO PARANÁ. <i>Revista Brasileira De Geociências</i>, <i>28</i>(4), 473–484. https://doi.org/10.25249/0375-7536.1998473484\n",
            "Adicionado - Tang, Y.-J., Zhang, H.-F., Santosh, M., &amp; Ying, J.-F..  (2013). Differential destruction of the North China Craton: A tectonic perspective. <i>Journal of Asian Earth Sciences</i>, <i>78</i>, 71–82. https://doi.org/10.1016/j.jseaes.2012.11.047\n",
            "Adicionado - RIOS, F. R., MIZUSAKI, A. M. P., &amp; MICHELIN, C. R. L..  (2018). FEIÇÕES DE INTERAÇÃO VULCANO-SEDIMENTARES: EXEMPLOS NA BACIA DO PARANÁ (RS). <i>Geosciences = Geociências</i>, <i>37</i>(3), 483–495. https://doi.org/10.5016/GEOCIENCIAS.V37I3.12172\n",
            "Adicionado - Matenco, L., Balázs, A., Nader, F. H., Haq, B. U., &amp; Fodor, L..  (2022). Advances in the understanding of multi-scale and coupled evolution of orogens, sedimentary basins and the underlying lithosphere. <i>Global and Planetary Change</i>, <i>208</i>, 103689. https://doi.org/10.1016/j.gloplacha.2021.103689\n",
            "Adicionado - Amaru, M..  (2007). <i>Global travel time tomography with 3-D reference models</i> (p. 174).\n",
            "Adicionado - O magmatismo toleítico da Bacia do Paraná.  (n.d.). O magmatismo toleítico da Bacia do Paraná.\n",
            "Adicionado - Tohver, E., Trindade, R. I. F., Solum, J. G., Hall, C. M., Riccomini, C., &amp; Nogueira, A. C..  (2010). Closing the Clymene ocean and bending a Brasiliano belt: Evidence for the Cambrian formation of Gondwana, southeast Amazon craton. <i>Geology</i>, <i>38</i>(3), 267–270. https://doi.org/10.1130/G30510.1\n",
            "Adicionado - Comin-Chiaramonti, P., Marzoli, A., de Barros Gomes, C., Milan, A., Riccomini, C., Velázquez, V. F., et al..  (2007). The origin of post-Paleozoic magmatism in eastern Paraguay (pp. 603–633). Geological Society of America. https://doi.org/10.1130/2007.2430(29)\n",
            "Adicionado - Lamarre, A. L., &amp; Hodder, R. W..  (1978). Distribution and genesis of fluorite deposits in the Western United States and their significance to metallogeny. <i>Geology</i>, <i>6</i>(4), 236. https://doi.org/10.1130/0091-7613(1978)6<236:DAGOFD>2.0.CO;2\n",
            "Adicionado - Peron-Pinvidic, G., Manatschal, G., &amp; Osmundsen, P. T..  (2013). Structural comparison of archetypal Atlantic rifted margins: A review of observations and concepts. <i>Marine and Petroleum Geology</i>, <i>43</i>, 21–47. https://doi.org/10.1016/j.marpetgeo.2013.02.002\n",
            "Adicionado - van der Meer, D. G., Spakman, W., van Hinsbergen, D. J. J., Amaru, M. L., &amp; Torsvik, T. H..  (2009). Towards absolute plate motions constrained by lower-mantle slab remnants. <i>Nature Geoscience</i>, <i>3</i>(1), 36–40. https://doi.org/10.1038/ngeo708\n",
            "Adicionado - Lamarre, A. L..  (1975). A model for subduction origin and distribution of fluorite deposits in the western United States. New Mexico Geological Society. https://doi.org/10.56577/FFC-26.169\n",
            "Adicionado - Philipp, R. P., Pimentel, M. M., &amp; Basei, M. A. S..  (2018). The Tectonic Evolution of the São Gabriel Terrane, Dom Feliciano Belt, Southern Brazil: The Closure of the Charrua Ocean (pp. 243–265). Springer International Publishing. https://doi.org/10.1007/978-3-319-68920-3_10\n",
            "Adicionado - Panetto, L. P., La Terra, E. F., Tupinambá, M., &amp; Fontes, S. L..  (2018). Crustal framework of the Ribeira and Brasília belts (SE Brazil) inferred from 3D magnetotelluric imaging. <i>Journal of South American Earth Sciences</i>, <i>86</i>, 342–352. https://doi.org/10.1016/j.jsames.2018.06.023\n",
            "Adicionado - Frank, H. T., Gomes, M. E. B., Formoso, M. L. L., &amp; Garcia, G. G..  (2007). Contaminação de flúor dos aquíferos da bacia do Paraná derivada da desgaseificação de intrusivas da Formação Serra Geral: nova hipótese. <i>Águas Subterrâneas</i>.\n",
            "Adicionado - Windley, B. F., Maruyama, S., &amp; Xiao, W. J..  (2010). Delamination/thinning of sub-continental lithospheric mantle under Eastern China: The role of water and multiple subduction. <i>American Journal of Science</i>, <i>310</i>(10), 1250–1293. https://doi.org/10.2475/10.2010.03\n",
            "Adicionado - Pysklywec, R. N., &amp; Quintas, M. C. L..  (2000). A mantle flow mechanism for the late Paleozoic subsidence of the Paraná Basin. <i>Journal of Geophysical Research: Solid Earth</i>, <i>105</i>(B7), 16359–16370. https://doi.org/10.1029/2000JB900080\n",
            "Adicionado - Moraes, L. C. de ., Seer, H. J., Janasi, V. de A., &amp; Valente Neto, F. de C..  (2020). Lithostratigraphy and volcanic facies architecture of the Paraná Continental Magmatic Province in its NE edge with the Alto Paranaíba Arch, Minas Gerais State, Brazil. <i>Brazilian Journal of Geology</i>, <i>50</i>(3). https://doi.org/10.1590/2317-4889202020200003\n",
            "Adicionado - Kearey, P..  (2014). <i>Tectônica Global</i> (p. 0).\n",
            "Adicionado - Silva, M. F. da ., Dantas, E. L., &amp; Vidotti, R. M..  (2021). Shortening history of the Neoproterozoic oroclinal bending in Paraguay belt, Central Brazil, based on structural interpretation of field work and high resolution aerogeophysical data. <i>Journal of South American Earth Sciences</i>, <i>107</i>, 103043. https://doi.org/10.1016/j.jsames.2020.103043\n",
            "Adicionado - Mantovani, M. S. M., Quintas, M. C. L., Shukowsky, W., &amp; Brito Neves, B. B..  (2005). Delimitation of the Paranapanema Proterozoic block: A geophysical contribution. <i>Episodes</i>, <i>28</i>(1), 18–22. https://doi.org/10.18814/epiiugs/2005/v28i1/002\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_56d2c957-58b0-4ba0-aee8-c68b4343cbf8\", \"references.html\", 24889)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Abrir CSL do repositorio público\n",
        "stylepath = get_style_filepath(csl_model)\n",
        "bib_style = CitationStylesStyle(stylepath, validate=False)\n",
        "\n",
        "output_text = ''  #acumular as referências em uma string\n",
        "reference_list = list()\n",
        "\n",
        "for bib in biblist:\n",
        "    # print(\"bib in biblist:\", bib)\n",
        "    for key, value in bib.items():\n",
        "        library = CitationStylesBibliography(bib_style, bib, formatter.html)\n",
        "        item = CitationItem(key)\n",
        "        library.register(Citation([item]))\n",
        "        try:\n",
        "          text = ''.join(library.style.render_bibliography([item])[0])\n",
        "          reference_list.append(text)\n",
        "          print(\"Adicionado - \" + text)\n",
        "        except Exception as e:\n",
        "          print(f'***Exception: Erro ao tratar informações de {item}')\n",
        "\n",
        "reference_list.sort()\n",
        "\n",
        "with open('references.html', 'w', encoding='utf-8') as f:\n",
        "    f.write('<html><head><title>References</title></head><body>')\n",
        "    for ref in reference_list:\n",
        "        f.write(f'<div>{ref}</div>')\n",
        "    f.write('</body></html>')\n",
        "\n",
        "files.download('references.html')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIvkqPKimbp1"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgczf+TEbfN+PihLhl6tVT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}